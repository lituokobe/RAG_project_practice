{
    "id": null,
    "metadata": {
        "source": "../datas/layout-parser-paper.pdf",
        "detection_class_prob": 0.9474897384643555,
        "coordinates": {
            "points": [
                [
                    373.62777777777774,
                    882.5920677777776
                ],
                [
                    373.62777777777774,
                    1076.310401111111
                ],
                [
                    1335.7128172182224,
                    1076.310401111111
                ],
                [
                    1335.7128172182224,
                    882.5920677777776
                ]
            ],
            "system": "PixelSpace",
            "layout_width": 1700,
            "layout_height": 2200
        },
        "last_modified": "2025-04-07T09:54:10",
        "filetype": "application/pdf",
        "languages": [
            "eng"
        ],
        "page_number": 9,
        "file_directory": "../datas",
        "filename": "layout-parser-paper.pdf",
        "category": "NarrativeText",
        "element_id": "fadd4ad54cd14e3e4711d41a1c99f813"
    },
    "page_content": "Fig. 3: Layout detection and OCR results visualization generated by the LayoutParser APIs. Mode I directly overlays the layout region bounding boxes and categories over the original image. Mode II recreates the original document via drawing the OCR’d texts at their corresponding positions on the image canvas. In this ﬁgure, tokens in textual regions are ﬁltered using the API and then displayed.",
    "type": "Document"
}